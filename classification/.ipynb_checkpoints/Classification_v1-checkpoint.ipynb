{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv   \n",
    "import cv2 as cv\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as mpplt\n",
    "import matplotlib.image as mpimg\n",
    "cmap = plt.cm.rainbow\n",
    "import matplotlib\n",
    "norm = matplotlib.colors.Normalize(vmin=0., vmax=1.)\n",
    "from helpers import *\n",
    "\n",
    "# # Load classification data\n",
    "\n",
    "\n",
    "path_to_load_data = os.path.join('.')\n",
    "\n",
    "X_modified = pd.read_csv(os.path.join(path_to_load_data,'spotData_withAnnotation.csv'), index_col=0)\n",
    "X_others = pd.read_csv( os.path.join(path_to_load_data,'spotData_withAnnotation_others.csv'), index_col=0)\n",
    "\n",
    "idx_spotWithSaturatedPixels = X_modified['numSaturatedPixels']>0\n",
    "X_modified = X_modified[~idx_spotWithSaturatedPixels]\n",
    "idx_spotWithSaturatedPixels = X_others['numSaturatedPixels']>0\n",
    "X_others = X_others[~idx_spotWithSaturatedPixels]\n",
    "\n",
    "\n",
    "print('X_modified',X_modified.shape)\n",
    "print('X_others',X_others.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_modified_lucas=X_modified.sort_values(['FOV_row', 'FOV_col'], ascending=[True, True])\n",
    "X_others_lucas=X_others.sort_values(['FOV_row', 'FOV_col'], ascending=[True, True])\n",
    "\n",
    "\n",
    "# # Classify using all data: X_modified and X_others\n",
    "\n",
    "# ### Add features\n",
    "\n",
    "\n",
    "\n",
    "X_modified[\"R/B\"] = X_modified[\"R\"] / X_modified[\"B\"]\n",
    "X_modified[\"G/B\"] = X_modified[\"G\"] / X_modified[\"B\"]\n",
    "\n",
    "X_others[\"R/B\"] = X_others[\"R\"] / X_others[\"B\"]\n",
    "X_others[\"G/B\"] = X_others[\"G\"] / X_others[\"B\"]\n",
    "\n",
    "print(\"X_modified: \",X_modified.shape)\n",
    "print(\"X_others: \",X_others.shape)\n",
    "\n",
    "\n",
    "columns_X_modified = list(X_modified.columns)\n",
    "columns_X_others = list(X_others.columns)\n",
    "print(\"columns_X_modified: \",columns_X_modified)\n",
    "print(\"columns_X_others: \",columns_X_others)\n",
    "\n",
    "\n",
    "# ### Get features \n",
    "\n",
    "\n",
    "\n",
    "features = ['R','G','B','R_max','G_max','B_max', 'lap_total','numPixels','numSaturatedPixels', 'R/B', 'G/B','overlap'] \n",
    "\n",
    "X_modified_ = X_modified[features]\n",
    "X_others_ = X_others[features]\n",
    "\n",
    "print(\"X_modified_: \",X_modified_.shape)\n",
    "print(\"X_others_: \",X_others_.shape)\n",
    "\n",
    "X_ = np.concatenate( [X_modified_, X_others_], axis=0) #to keep others\n",
    "#X_ = X_modified_ # to exclude others\n",
    "\n",
    "X = np.concatenate( [X_modified, X_others], axis=0)\n",
    "#X = X_modified # to exclude others\n",
    "\n",
    "\n",
    "print(\"X_: \",X_.shape)\n",
    "print(\"X: \",X.shape)\n",
    "\n",
    "\n",
    "# ### Get labels\n",
    "\n",
    "\n",
    "\n",
    "labels = ['Annotation'] \n",
    "\n",
    "# get labels\n",
    "y_modified = X_modified[labels]\n",
    "y_others = X_others[labels]\n",
    "print(\"y_modified: \", y_modified.shape)\n",
    "print('y_modified: ', np.unique(y_modified, return_counts=True))\n",
    "print(\"y_others: \", y_others.shape)\n",
    "print('y_others: ', np.unique(y_others, return_counts=True))\n",
    "\n",
    "\n",
    "y = np.concatenate([y_modified,y_others]) #to keep others\n",
    "#y = y_modified # to exclude others\n",
    "\n",
    "y = np.asarray(y).flatten()\n",
    "print('y: ', np.unique(y, return_counts=True))\n",
    "\n",
    "# convert labels to 0 / 1\n",
    "y[y=='Parasite'] = 1\n",
    "y[y=='Platelet'] = 0\n",
    "y[y=='Others'] = 2\n",
    "print(\"y: \", y.shape)\n",
    "print(np.unique(y, return_counts=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Classification on full dataset\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "\n",
    "kernel = 'linear'\n",
    "class_names = np.asarray(['platelet', 'parasite', 'other'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# convert y from object to numbers \n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "print(\"y before : \", type_of_target(y))\n",
    "#print(\"y before : \", y)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "print(\"y after: \", type_of_target(y))\n",
    "#print(\"y after : \", y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "#i = 0\n",
    "\n",
    "#for train_index, test_index in skf.split(X_, y):\n",
    "X_train_, X_test_ = X_, X_\n",
    "y_train, y_test = y, y\n",
    "\n",
    "X_train, X_test = X, X\n",
    "\n",
    "\n",
    "print(\"============= NEW SPLIT =============\")\n",
    "print(\"X_train_: \",X_train_.shape)\n",
    "print(\"X_test_: \",X_test_.shape)\n",
    "print(\"y_train: \",y_train.shape)\n",
    "print(\"y_test: \",y_test.shape)\n",
    "print(\"y_train: \", np.unique(y_train, return_counts=True))\n",
    "print(\"y_test: \", np.unique(y_test, return_counts=True))\n",
    "\n",
    "print(\"X_train: \",X_train.shape)\n",
    "print(\"X_test: \",X_test.shape)\n",
    "\n",
    "# Normalize train data. \n",
    "mean = np.mean(X_train_, axis=0,keepdims=True)\n",
    "std = np.std(X_train_, axis=0,keepdims=True)\n",
    "X_train_ = (X_train_ - mean) / (std + 1e-8)\n",
    "print(\"X_train_ after normalization: \",X_train_.shape)\n",
    "# Normalize test data. Note: We use train mean+variance. Note: Do not normalize overlap! \n",
    "X_test_ = (X_test_ - mean) / (std + 1e-8)\n",
    "print(\"X_test_ after normalization: \",X_test_.shape)\n",
    "\n",
    "# Shuffle train data\n",
    "p_train = np.random.permutation(len(y_train))\n",
    "X_train_ = X_train_[p_train]\n",
    "y_train = y_train[p_train]\n",
    "X_train = X_train[p_train]\n",
    "\n",
    "# Shuffle test data\n",
    "p_test = np.random.permutation(len(y_test))\n",
    "X_test_ = X_test_[p_test]\n",
    "y_test = y_test[p_test]\n",
    "X_test = X_test[p_test]\n",
    "print('y_train',np.unique(y_train,return_counts=True))\n",
    "print('y_test',np.unique(y_test,return_counts=True))\n",
    "\n",
    "\n",
    "########################################\n",
    "# TRAINING\n",
    "########################################\n",
    "\n",
    "# Create classifier\n",
    "clf = svm.SVC(kernel=kernel, gamma=10, probability=True, random_state=10)\n",
    "#clf = RandomForestClassifier(max_depth=50, n_estimators=100, max_features=1) \n",
    "\n",
    "# Train classifier to predict parasites vs rest of the world\n",
    "y_train[y_train == 2] = 0\n",
    "y_test[y_test == 2] = 0\n",
    "print('y_train',np.unique(y_train,return_counts=True))\n",
    "print('y_test',np.unique(y_test,return_counts=True))\n",
    "\n",
    "# Train classifier\n",
    "train_fit = clf.fit(X_train_, y_train)\n",
    "\n",
    "\n",
    "#Deploy classifier on training set\n",
    "dtrain_predprob = clf.predict_proba(X_train_)[:,1]\n",
    "dtrain_pred = clf.predict(X_train_)\n",
    "\n",
    "#Deploy classifier on test set\n",
    "dtest_predprob = clf.predict_proba(X_test_)[:,1]\n",
    "dtest_pred = clf.predict(X_test_)\n",
    "\n",
    "\n",
    "########################################\n",
    "# PLOT RESULTS\n",
    "########################################\n",
    "\n",
    "i=0 \n",
    "\n",
    "# Compute ROC curve and area the curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, dtest_predprob)\n",
    "tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "tprs[-1][0] = 0.0\n",
    "roc_auc = auc(fpr, tpr)\n",
    "aucs.append(roc_auc)\n",
    "plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "         label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"X_train: \",X_train.shape)\n",
    "print(\"X_test: \",X_test.shape)\n",
    "\n",
    "print(\"dtest_predprob: \",dtest_predprob.shape)\n",
    "print(\"dtest_pred: \",dtest_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dtrain_predprob = np.reshape(dtrain_predprob, [-1,1])\n",
    "dtrain_pred = np.reshape(dtrain_pred, [-1,1])\n",
    "print(\"dtrain_predprob: \",dtrain_predprob.shape)\n",
    "print(\"dtrain_pred: \",dtrain_pred.shape)\n",
    "\n",
    "dtest_predprob = np.reshape(dtest_predprob, [-1,1])\n",
    "dtest_pred = np.reshape(dtest_pred, [-1,1])\n",
    "print(\"dtest_predprob: \",dtest_predprob.shape)\n",
    "print(\"dtest_pred: \",dtest_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.hstack((X_train,dtrain_predprob))\n",
    "X_train = np.hstack((X_train,dtrain_pred))\n",
    "print(\"X_train: \",X_train.shape)\n",
    "\n",
    "X_test = np.hstack((X_test,dtest_predprob))\n",
    "X_test = np.hstack((X_test,dtest_pred))\n",
    "print(\"X_test: \",X_test.shape)\n",
    "\n",
    "columns_X_modified.append(\"predprob\")\n",
    "columns_X_modified.append(\"pred\")\n",
    "columns_X_others.append(\"predprob\")\n",
    "columns_X_others.append(\"pred\")\n",
    "\n",
    "\n",
    "# ### Save X_train and X_dev to disk\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# check that both are equal\n",
    "print(\"columns_X_modified: \",columns_X_modified)\n",
    "print(\"columns_X_others: \",columns_X_others)\n",
    "\n",
    "print('----------------------------')\n",
    "print(X_train.shape)\n",
    "print(len(columns_X_others))\n",
    "print('----------------------------')\n",
    "\n",
    "\n",
    "\n",
    "# df_X_train = pd.DataFrame(data=X_train, columns=columns_X_modified)\n",
    "# df_X_test = pd.DataFrame(data=X_test, columns=columns_X_modified)\n",
    "\n",
    "df_X_train = pd.DataFrame(data=X_train, columns=columns_X_modified)\n",
    "df_X_test = pd.DataFrame(data=X_test, columns=columns_X_modified)\n",
    "\n",
    "\n",
    "\n",
    "df_X_train.head(55)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_X_test.head(15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_X_train.to_csv('./X_train.csv', index=True)\n",
    "df_X_test.to_csv('./X_test.csv', index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_X_train.shape\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
