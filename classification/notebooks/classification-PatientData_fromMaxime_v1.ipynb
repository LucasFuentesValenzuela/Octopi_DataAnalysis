{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-classification-data\" data-toc-modified-id=\"Load-classification-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load classification data</a></span></li><li><span><a href=\"#Remove-FOVs-which-are-corrupted-(round-2!)\" data-toc-modified-id=\"Remove-FOVs-which-are-corrupted-(round-2!)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Remove FOVs which are corrupted (round 2!)</a></span></li><li><span><a href=\"#t-SNE-plot-(requires-normalization)\" data-toc-modified-id=\"t-SNE-plot-(requires-normalization)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>t-SNE plot (requires normalization)</a></span></li><li><span><a href=\"#Plot-R/B-vs-G/B-(without-normalization)\" data-toc-modified-id=\"Plot-R/B-vs-G/B-(without-normalization)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Plot R/B vs G/B (without normalization)</a></span></li><li><span><a href=\"#Plot-histogram-of-total-intensity-for-all-whole-blood-slides\" data-toc-modified-id=\"Plot-histogram-of-total-intensity-for-all-whole-blood-slides-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Plot histogram of total intensity for all whole blood slides</a></span></li><li><span><a href=\"#Plot-histogram-of-size--for-all-whole-blood-slides\" data-toc-modified-id=\"Plot-histogram-of-size--for-all-whole-blood-slides-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Plot histogram of size  for all whole blood slides</a></span></li><li><span><a href=\"#Create-cross-validation-folds\" data-toc-modified-id=\"Create-cross-validation-folds-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Create cross-validation folds</a></span></li><li><span><a href=\"#Train-model-using-cross-validation\" data-toc-modified-id=\"Train-model-using-cross-validation-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Train model using cross-validation</a></span></li><li><span><a href=\"#Plot-results\" data-toc-modified-id=\"Plot-results-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Plot results</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Load-results\" data-toc-modified-id=\"Load-results-9.0.1\"><span class=\"toc-item-num\">9.0.1&nbsp;&nbsp;</span>Load results</a></span></li><li><span><a href=\"#Show-results\" data-toc-modified-id=\"Show-results-9.0.2\"><span class=\"toc-item-num\">9.0.2&nbsp;&nbsp;</span>Show results</a></span></li><li><span><a href=\"#Identify-which-AUC-curve-is-the-closest-to-the-mean-one-(e.g.-compare-AUCs-to-mean-AUC)\" data-toc-modified-id=\"Identify-which-AUC-curve-is-the-closest-to-the-mean-one-(e.g.-compare-AUCs-to-mean-AUC)-9.0.3\"><span class=\"toc-item-num\">9.0.3&nbsp;&nbsp;</span>Identify which AUC curve is the closest to the mean one (e.g. compare AUCs to mean AUC)</a></span><ul class=\"toc-item\"><li><span><a href=\"#FPR-vs-FNR-curves\" data-toc-modified-id=\"FPR-vs-FNR-curves-9.0.3.1\"><span class=\"toc-item-num\">9.0.3.1&nbsp;&nbsp;</span>FPR vs FNR curves</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv   \n",
    "import cv2 as cv\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import gaussian_kde\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as mpplt\n",
    "import matplotlib.image as mpimg\n",
    "cmap = plt.cm.rainbow\n",
    "import matplotlib\n",
    "norm = matplotlib.colors.Normalize(vmin=0., vmax=1.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop image\n",
    "x_low = 821\n",
    "x_high = 1643\n",
    "y_low = 819\n",
    "y_high = 1640\n",
    "crop_box = [x_low,x_high,y_low,y_high]\n",
    "\n",
    "# Top-hat filtering kernel\n",
    "disk_diameter = 17\n",
    "kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (int(disk_diameter), int(disk_diameter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('df_with_helper_with_overlap', (873, 54))\n",
      "('y', (873,))\n",
      "('y', (array([0., 1.]), array([549, 324])))\n"
     ]
    }
   ],
   "source": [
    "path_to_load_data = os.path.join('..','data','output_step_3_combine_fluo_and_brightfield_features')\n",
    "\n",
    "X_with_helpers_with_overlap = pd.read_csv(os.path.join(path_to_load_data,'df_with_helper_with_overlap.csv'),index_col=0)\n",
    "y = np.genfromtxt( os.path.join(path_to_load_data,'y.csv') , delimiter=',')\n",
    "\n",
    "print('df_with_helper_with_overlap',X_with_helpers_with_overlap.shape)\n",
    "print('y',y.shape)\n",
    "print('y',np.unique(y,return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove FOVs which are corrupted (round 2!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOVs to remove\n",
    "FOV_to_remmove = {\n",
    "    '1128-w-16': ['_0002_0001_fluorescent.jpeg','_0006_0004_fluorescent.jpeg','_0009_0004_fluorescent.jpeg','_0010_0002_fluorescent.jpeg'],\n",
    "    '1128-w-17': ['_0006_0000_fluorescent.jpeg','_0006_0001_fluorescent.jpeg','_0007_0002_fluorescent.jpeg','_0008_0010_fluorescent.jpeg','_0009_0011_fluorescent.jpeg','_0010_0004_fluorescent.jpeg','_0010_0005_fluorescent.jpeg','_0010_0007_fluorescent.jpeg','_0012_0008_fluorescent.jpeg','_0012_0010_fluorescent.jpeg','_0012_0011_fluorescent.jpeg','_0013_0009_fluorescent.jpeg'],\n",
    "    '1128-w-18': ['_0001_0010_fluorescent.jpeg','_0003_0011_fluorescent.jpeg','_0005_0004_fluorescent.jpeg','_0008_0011_fluorescent.jpeg','_0009_0000_fluorescent.jpeg','_0010_0009_fluorescent.jpeg','_0011_0009_fluorescent.jpeg','_0011_0010_fluorescent.jpeg','_0011_0011_fluorescent.jpeg'],\n",
    "    '1128-w-19': ['_0001_0008_fluorescent.jpeg','_0003_0005_fluorescent.jpeg','_0004_0008_fluorescent.jpeg','_0005_0008_fluorescent.jpeg','_0007_0000_fluorescent.jpeg','_0007_0006_fluorescent.jpeg','_0007_0009_fluorescent.jpeg','_0009_0003_fluorescent.jpeg','_0009_0004_fluorescent.jpeg'],\n",
    "    '1128-w-20': ['_0001_0002_fluorescent.jpeg','_0001_0008_fluorescent.jpeg','_0003_0008_fluorescent.jpeg','_0005_0009_fluorescent.jpeg','_0007_0006_fluorescent.jpeg','_0007_0009_fluorescent.jpeg','_0007_0011_fluorescent.jpeg','_0008_0004_fluorescent.jpeg','_0009_0010_fluorescent.jpeg'],\n",
    "    '1128-w-31': ['_0001_0009_fluorescent.jpeg','_0004_0007_fluorescent.jpeg'],\n",
    "    '1128-w-32': ['_0003_0001_fluorescent.jpeg', '_0008_0004_fluorescent.jpeg','_0008_0006_fluorescent.jpeg'],\n",
    "    '1128-w-41': ['_0001_0007_fluorescent.jpeg', '_0001_0009_fluorescent.jpeg', '_0001_0011_fluorescent.jpeg','_0002_0008_fluorescent.jpeg','_0006_0004_fluorescent.jpeg','_0011_0005_fluorescent.jpeg','_0011_0009_fluorescent.jpeg','_0012_0009_fluorescent.jpeg'],\n",
    "    '1128-w-42': ['_0003_0006_fluorescent.jpeg','_0006_0002_fluorescent.jpeg','_0007_0000_fluorescent.jpeg','_0008_0003_fluorescent.jpeg'],\n",
    "    '1128-w-43': ['_0003_0001_fluorescent.jpeg','_0004_0005_fluorescent.jpeg','_0005_0006_fluorescent.jpeg','_0006_0001_fluorescent.jpeg','_0006_0008_fluorescent.jpeg','_0007_0001_fluorescent.jpeg','_0007_0003_fluorescent.jpeg','_0007_0011_fluorescent.jpeg','_0009_0001_fluorescent.jpeg','_0010_0007_fluorescent.jpeg','_0012_0006_fluorescent.jpeg','_0012_0011_fluorescent.jpeg','_0013_0010_fluorescent.jpeg','_0014_0010_fluorescent.jpeg'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_with_helpers_with_overlap', (873, 54))\n",
      "('y', (873,))\n",
      "('y', (array([0., 1.]), array([549, 324])))\n"
     ]
    }
   ],
   "source": [
    "idx_to_remove_global = [False]*X_with_helpers_with_overlap.shape[0]\n",
    "\n",
    "# Iterate over patients\n",
    "for patient_id, FOV_ids in FOV_to_remmove.iteritems():\n",
    "    # Iterate over FOVs\n",
    "    for FOV_id in FOV_ids: \n",
    "        # Identify spots corresponding to patients+FOVs to remove\n",
    "        idx_to_remove_1 = (X_with_helpers_with_overlap['foldername'].values==patient_id)\n",
    "        idx_to_remove_2 = (X_with_helpers_with_overlap['filename'].values==FOV_id)\n",
    "        idx_to_remove = np.logical_and(idx_to_remove_1,idx_to_remove_2)\n",
    "        idx_to_remove_global = np.logical_or(idx_to_remove_global,idx_to_remove)\n",
    "        \n",
    "# Remove spots\n",
    "X_with_helpers_with_overlap = X_with_helpers_with_overlap[~idx_to_remove_global].reset_index(drop=True)\n",
    "y = y[~idx_to_remove_global]\n",
    "\n",
    "#print('X_with_overlap',X_with_overlap.shape)\n",
    "print('X_with_helpers_with_overlap',X_with_helpers_with_overlap.shape)\n",
    "print('y',y.shape)\n",
    "print('y',np.unique(y,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_with_helpers_with_overlap', (873, 54))\n",
      "('X_with_overlap', (873, 51))\n"
     ]
    }
   ],
   "source": [
    "cols_to_keep = [x for x in list(X_with_helpers_with_overlap.columns) if x not in ['filename','foldername','spot_idx'] ]\n",
    "\n",
    "X_with_overlap = X_with_helpers_with_overlap[cols_to_keep]\n",
    "print('X_with_helpers_with_overlap',X_with_helpers_with_overlap.shape)\n",
    "print('X_with_overlap',X_with_overlap.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE plot (requires normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_for_tsne', (873, 51))\n",
      "('y_for_tsne', (873,))\n",
      "('X_for_tsne_scaled', (873, 51))\n"
     ]
    }
   ],
   "source": [
    "X_for_tsne = np.copy(X_with_overlap)\n",
    "y_for_tsne = np.copy(y)\n",
    "# Shuffle data\n",
    "idx_to_shuffle = np.random.permutation(len(y_for_tsne))\n",
    "X_for_tsne = X_for_tsne[idx_to_shuffle]\n",
    "y_for_tsne = y_for_tsne[idx_to_shuffle]\n",
    "print('X_for_tsne',X_for_tsne.shape)\n",
    "print('y_for_tsne',y_for_tsne.shape)\n",
    "# Scale + center data for t-SNE\n",
    "X_for_tsne_scaled = preprocessing.scale(X_for_tsne)\n",
    "print('X_for_tsne_scaled',X_for_tsne_scaled.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 9394 is out of bounds for axis 0 with size 549",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ad995e36b54b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0midx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_spots_for_tsne\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0midx_tsne_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_for_tsne\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0midx_tsne_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_for_tsne\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'idx_tsne_0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_tsne_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 9394 is out of bounds for axis 0 with size 549"
     ]
    }
   ],
   "source": [
    "# Extract 10k fluo spots from each class, for t-SNE plots\n",
    "n_spots_for_tsne = 10000\n",
    "np.random.seed(0)\n",
    "\n",
    "idx_ = np.random.permutation(n_spots_for_tsne)\n",
    "\n",
    "idx_tsne_0 = np.where(y_for_tsne==0.)[0][idx_]\n",
    "idx_tsne_1 = np.where(y_for_tsne==1.)[0][idx_]\n",
    "print('idx_tsne_0',idx_tsne_0)\n",
    "print('idx_tsne_1',idx_tsne_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_tsne = np.array(list(idx_tsne_0) + list(idx_tsne_1))\n",
    "print('idx_tsne',idx_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_for_tsne_scaled = X_for_tsne_scaled[idx_tsne]\n",
    "y_for_tsne = y_for_tsne[idx_tsne]\n",
    "print('X_for_tsne_scaled',X_for_tsne_scaled.shape)\n",
    "print('y_for_tsne',y_for_tsne.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run t-SNE \n",
    "X_for_tsne_ = TSNE(n_components=2, random_state=6).fit_transform(X_for_tsne_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_PF = X_for_tsne_[:,0][y_for_tsne==1.]\n",
    "x_WB = X_for_tsne_[:,0][y_for_tsne==0.]\n",
    "print('x_PF',x_PF.shape)\n",
    "print('x_WB',x_WB.shape)\n",
    "\n",
    "y_PF = X_for_tsne_[:,1][y_for_tsne==1.]\n",
    "y_WB = X_for_tsne_[:,1][y_for_tsne==0.]\n",
    "print('y_PF',y_PF.shape)\n",
    "print('y_WB',y_WB.shape)\n",
    "\n",
    "# dscatter \n",
    "# http://localhost:8000/notebooks/Box/Malariascope_Paper_TeamFolder/Maxime/Malaria%20Detection/classification/main_classification.ipynb#\n",
    "xy_PF = np.vstack([x_PF,y_PF])\n",
    "z_PF = gaussian_kde(xy_PF)(xy_PF)\n",
    "xy_WB = np.vstack([x_WB,y_WB])\n",
    "z_WB = gaussian_kde(xy_WB)(xy_WB)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(x_PF, y_PF, c=z_PF, s=8, edgecolor='',marker='o',cmap='autumn')\n",
    "plt.scatter(x_WB, y_WB, c=z_WB, s=8, edgecolor='',marker='o',cmap='winter')\n",
    "#plt.show()\n",
    "plt.savefig('tsne_v2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Save t-sne data to disk\n",
    "np.savetxt(\"X_for_tsne_v2_.csv\", X_for_tsne_, delimiter=\",\")\n",
    "np.savetxt(\"y_for_tsne_v2_.csv\", y_for_tsne, delimiter=\",\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot R/B vs G/B (without normalization) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_with_overlap',X_with_overlap.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get R/B: is it a feature already? or should i compute it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ = X_with_overlap['R_int'].values\n",
    "B_ = X_with_overlap['B_int'].values\n",
    "\n",
    "R_over_B = R_/(B_+0.1) #+0.1 can be deleted if B_ doesnt have a 0...\n",
    "plt.hist(R_over_B, normed=True, bins=70)\n",
    "plt.ylabel('Probability')\n",
    "plt.xlim(0.,2.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get G/B: is it a feature already? or should i compute it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_over_B = X_with_overlap['G_int/B_int'].values\n",
    "print('G_over_B',G_over_B)\n",
    "\n",
    "plt.hist(G_over_B, normed=True, bins=70)\n",
    "plt.ylabel('Probability')\n",
    "\n",
    "plt.xlim(0.,2.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot R/B vs G/B. Color code for y=0 and y=1\n",
    "#print('G_over_B',G_over_B.shape)\n",
    "#print('R_over_B',R_over_B.shape)\n",
    "idx_0 = (y==0)\n",
    "G_over_B_0 = G_over_B[idx_0]\n",
    "R_over_B_0 = R_over_B[idx_0]\n",
    "print('G_over_B_0',G_over_B_0.shape)\n",
    "print('R_over_B_0',R_over_B_0.shape)\n",
    "idx_1 = (y==1)\n",
    "G_over_B_1 = G_over_B[idx_1]\n",
    "R_over_B_1 = R_over_B[idx_1]\n",
    "print('G_over_B_1',G_over_B_1.shape)\n",
    "print('R_over_B_1',R_over_B_1.shape)\n",
    "\n",
    "plt.scatter(G_over_B_0, R_over_B_0, s=0.005, c='green',alpha=0.7) #, s=area, c=colors, alpha=0.5)\n",
    "plt.scatter(G_over_B_1, R_over_B_1, s=0.005, c='red',alpha=0.7) #, s=area, c=colors, alpha=0.5)\n",
    "plt.title('Scatter plot R_over_B vs G_over_B')\n",
    "plt.xlabel('G_over_B')\n",
    "plt.ylabel('R_over_B')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot histogram of total intensity for all whole blood slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with_overlap.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sumRBG_int\n",
    "sumRBG_int = X_with_overlap['sumRBG_int'].values\n",
    "# Get WB slides \n",
    "idx_WB = (y==0)\n",
    "print('idx_WB',np.sum(idx_WB))\n",
    "# Keep sumRBG_int for WB slides\n",
    "sumRBG_int_WB = sumRBG_int[idx_WB]\n",
    "\n",
    "plt.hist(sumRBG_int_WB, normed=True, bins=70)\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Histogram of total spot intensity for all whole blood slides')\n",
    "\n",
    "#plt.xlim(0.,2.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot histogram of size  for all whole blood slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Get sumRBG_int\n",
    "sumRBG_int = X_with_overlap['sumRBG_int'].values\n",
    "# Get sumRBG_int/NumPix\n",
    "sumRBG_int_over_NumPix = X_with_overlap['sumRBG_int/NumPix'].values\n",
    "# Get NumPix\n",
    "NumPix = sumRBG_int/sumRBG_int_over_NumPix\n",
    "\n",
    "# Get WB slides \n",
    "idx_WB = (y==0)\n",
    "print('idx_WB',np.sum(idx_WB))\n",
    "# Keep NumPix for WB slides\n",
    "NumPix_WB = NumPix[idx_WB]\n",
    "\n",
    "plt.hist(NumPix_WB, normed=True, bins=100)\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Histogram of spot size for all whole blood slides')\n",
    "plt.yscale('log')\n",
    "#plt.xlim(0.,2.3)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cross-validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n_folds = 20\n",
    "\n",
    "# List patients\n",
    "slides_PF = ['1128-p-63', '1128-p-64', '1128-p-66', '1128-p-67', '1128-p-74', '1128-p-75', '1128-p-76b', '1128-p-79']\n",
    "slides_WB = ['1128-w-16', '1128-w-17', '1128-w-18', '1128-w-19', '1128-w-20', '1128-w-31', '1128-w-32', '1128-w-41', '1128-w-42', '1128-w-43']\n",
    "print('slides_PF',len(slides_PF))\n",
    "print('slides_WB',len(slides_WB))\n",
    "\n",
    "folds = {}\n",
    "for i in range(n_folds): \n",
    "    # Pick 3 PF slides\n",
    "    fold_slides_PF = list(np.random.choice(slides_PF, size=3, replace=False))\n",
    "    # Pick 3 WB slides\n",
    "    fold_slides_WB = list(np.random.choice(slides_WB, size=3, replace=False))\n",
    "    folds['fold_'+str(i)] = fold_slides_PF + fold_slides_WB\n",
    "    \n",
    "# Get idx corresponding to each fold\n",
    "fold_idx = {}\n",
    "# Iterate over folds\n",
    "for fold, fold_folders in folds.iteritems():\n",
    "    # Get test idx \n",
    "    test_idx = X_with_helpers_with_overlap['foldername'].isin(fold_folders)\n",
    "    fold_idx[fold] = test_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model using cross-validation\n",
    "\n",
    "We iterate over folds. For each fold: \n",
    "- We get train data and test data\n",
    "- We normalize train and test data seperately\n",
    "- Shuffle the rows of train data and test data, respectively\n",
    "- We train on train set, and evaluate and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'learning_rate':0.10, #0.10 \n",
    "    'n_estimators': 233, #233, \n",
    "    'max_depth':6, # 6 \n",
    "    'min_child_weight': 10, #10 \n",
    "    'gamma': 1., # 1. \n",
    "    'subsample':1., # 1. \n",
    "    'colsample_bytree':1., #1. \n",
    "    'objective':'binary:logistic',\n",
    "    'nthread':-1,\n",
    "    'scale_pos_weight':1., #1. \n",
    "    'seed':2, # 2\n",
    "    'reg_lambda':30., # 30. \n",
    "    'reg_alpha':0., # 0. \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [x for x in list(X_with_helpers_with_overlap.columns.values) if x not in ['filename','foldername', 'spot_idx'] ]\n",
    "X_ = X_with_helpers_with_overlap[columns_to_keep]\n",
    "print('X_with_helpers_with_overlap',X_with_helpers_with_overlap.shape)\n",
    "print('X_',X_.shape)\n",
    "print('y',y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fnrs_global,fprs_global,thresholds_global,fold_global,auc_global,fpr_value_global,fnr_value_global = [],[],[],[],[],[],[]\n",
    "\n",
    "# Iterate over folds\n",
    "for fold, test_idx in fold_idx.iteritems():\n",
    "    print('======== ',fold)\n",
    "    foldername_k_global,filename_k_global,spot_idx_k_global,overlap_k_global = [],[],[],[]\n",
    "    \n",
    "    # Get train data\n",
    "    X_train = X_[~test_idx]\n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = y[~test_idx]\n",
    "    # Get test data\n",
    "    X_test = X_[test_idx]\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = y[test_idx]\n",
    "\n",
    "    # Normalize train data. Note: Do not normalize overlap! \n",
    "    X_train_1 = X_train[:,:-1]\n",
    "    X_train_2 = X_train[:,-1:]\n",
    "    mean_1 = np.mean(X_train_1, axis=0,keepdims=True)\n",
    "    std_1 = np.std(X_train_1, axis=0,keepdims=True)\n",
    "    X_train_1 = (X_train_1 - mean_1) / (std_1 + 1e-8)\n",
    "    X_train = np.concatenate([X_train_1,X_train_2],axis=1)\n",
    "    # Normalize test data. Note: We use train mean+variance. Note: Do not normalize overlap! \n",
    "    X_test_1 = X_test[:,:-1]\n",
    "    X_test_2 = X_test[:,-1:]\n",
    "    X_test_1 = (X_test_1 - mean_1) / (std_1 + 1e-8)\n",
    "    X_test = np.concatenate([X_test_1,X_test_2],axis=1)\n",
    "\n",
    "    # Shuffle train data\n",
    "    p_train = np.random.permutation(len(y_train))\n",
    "    X_train = X_train[p_train]\n",
    "    y_train = y_train[p_train]\n",
    "    # Shuffle test data\n",
    "    p_test = np.random.permutation(len(y_test))\n",
    "    X_test = X_test[p_test]\n",
    "    y_test = y_test[p_test]\n",
    "    print('y_train',np.unique(y_train,return_counts=True))\n",
    "    print('y_test',np.unique(y_test,return_counts=True))\n",
    "\n",
    "    ########################################\n",
    "    # TRAINING\n",
    "    ########################################\n",
    "    # Create XGBClassifier\n",
    "    xgb = XGBClassifier(**params)\n",
    "    # Train XGBClassifier\n",
    "    train_fit = xgb.fit(X_train, y_train)\n",
    "\n",
    "    #Deploy XGBClassifier on training set\n",
    "    dtrain_predprob = xgb.predict_proba(X_train)[:,1]\n",
    "    print('Train AUC: ', metrics.roc_auc_score(y_train, dtrain_predprob) )\n",
    "    #Deploy XGBClassifier on test set\n",
    "    dtest_predprob = xgb.predict_proba(X_test)[:,1]\n",
    "    auc = metrics.roc_auc_score(y_test, dtest_predprob)\n",
    "    print('Test AUC: ', auc)\n",
    "\n",
    "    # Find decision threshold to match FNR just under 10%\n",
    "    target_fnr_value = 0.1\n",
    "    fprs, tprs, thresholds = metrics.roc_curve(y_test, dtest_predprob)\n",
    "    fnrs = 1. - tprs\n",
    "    idx_my_decision_threshold = np.where( fnrs < target_fnr_value )[0][0]\n",
    "    decision_threshold = thresholds[idx_my_decision_threshold]\n",
    "    fpr_value_ = fprs[idx_my_decision_threshold]\n",
    "    fnr_value_ = fnrs[idx_my_decision_threshold]\n",
    "    dtest_predprob_binarized = 1.*(dtest_predprob>=decision_threshold)\n",
    "    tn_, fp_, fn_, tp_ = metrics.confusion_matrix(y_test, dtest_predprob_binarized).ravel()\n",
    "    print('nb of fp_: ',fp_)\n",
    "    print('nb of fn_: ',fn_)\n",
    "    print('fpr_value_: ',fpr_value_)\n",
    "    print('fnr_value_: ',fnr_value_)\n",
    "    # print results\n",
    "    print('The FPR corresponding to a FNR of '+str(fnr_value_)+' is: %.6g' % fpr_value_) \n",
    "\n",
    "    # Book keeping\n",
    "    fnrs_global.append(fnrs)\n",
    "    fprs_global.append(fprs)\n",
    "    thresholds_global.append(thresholds)\n",
    "    fold_global.append(fold)\n",
    "    auc_global.append(auc)\n",
    "    fpr_value_global.append(fpr_value_)\n",
    "    fnr_value_global.append(fnr_value_)\n",
    "\n",
    "    ########################################\n",
    "    # Error analysis: plot mispredicted (FP, FN) for error analysis\n",
    "    ########################################\n",
    "\n",
    "    # Get FP spots\n",
    "    idx_FP = np.logical_and(dtest_predprob_binarized==1,y_test==0)\n",
    "    X_test_FP = X_test[idx_FP]\n",
    "    list_idx_FP = np.where(idx_FP)\n",
    "    list_idx_FP = list(list_idx_FP[0])\n",
    "    print('list_idx_FP',len(list_idx_FP))\n",
    "    # Get FN spots\n",
    "    idx_FN = np.logical_and(dtest_predprob_binarized==0,y_test==1)\n",
    "    X_test_FN = X_test[idx_FN]\n",
    "    list_idx_FN = np.where(idx_FN)\n",
    "    list_idx_FN = list(list_idx_FN[0])\n",
    "    print('list_idx_FN',len(list_idx_FN))\n",
    "\n",
    "    X_test_ = X_with_helpers_with_overlap[test_idx]\n",
    "    X_test_ = X_test_.reset_index(drop=True)\n",
    "    X_test_ = X_test_.reindex(p_test)\n",
    "    X_test_ = X_test_.reset_index(drop=True)\n",
    "    # FP\n",
    "    X_test_FP_ = X_test_[idx_FP]\n",
    "    X_test_FP_ = X_test_FP_.reset_index(drop=True)\n",
    "    # FN\n",
    "    X_test_FN_ = X_test_[idx_FN]\n",
    "    X_test_FN_ = X_test_FN_.reset_index(drop=True)\n",
    "\n",
    "    n_FP = X_test_FP.shape[0]\n",
    "    n_FP_ = min(n_FP,30)\n",
    "    prev_filename_k = ''\n",
    "    prev_foldername_k = ''\n",
    "    # Iterate over FPs\n",
    "    for k in range(n_FP_):\n",
    "        # Get meta features\n",
    "        X_test_FP_k = X_test_FP_.iloc[k]\n",
    "        foldername_k = X_test_FP_k['foldername']\n",
    "        filename_k = X_test_FP_k['filename']\n",
    "        spot_idx_k = X_test_FP_k['spot_idx']\n",
    "        overlap_k = X_test_FP_k['overlap']\n",
    "        \n",
    "        if (foldername_k!=prev_foldername_k) or (filename_k!=prev_filename_k):\n",
    "            # Load corresponding img\n",
    "            path_to_patient = os.path.join('..','data',foldername_k)\n",
    "            path_to_fluo_imgs = os.path.join( path_to_patient,'raw_data','fluorescent' )\n",
    "            path_to_fluo_img = os.path.join(path_to_fluo_imgs,filename_k)\n",
    "            if not os.path.isfile(path_to_fluo_img):\n",
    "                raise ValueError('Image does not exist',foldername_k,filename_k,path_to_fluo_img)\n",
    "            img_fluo_raw = mpimg.imread(path_to_fluo_img)\n",
    "            # Rescale image to [0,1]\n",
    "            img_fluo_raw = img_fluo_raw/255.\n",
    "            # Crop image \n",
    "            x_low,x_high,y_low,y_high = crop_box\n",
    "            img_fluo_raw = img_fluo_raw[x_low:x_high,y_low:y_high,:]\n",
    "            # Morphological top-hat transform filtering on each channel of the fluo image\n",
    "            # We compute the morphological opening of each channel, and then subtracts the result from the original channel\n",
    "            tophat_filter = np.zeros_like(img_fluo_raw)\n",
    "            for c in range(img_fluo_raw.shape[-1]):\n",
    "                tophat_filter[:,:,c] = cv.morphologyEx(img_fluo_raw[:,:,c], cv.MORPH_OPEN, kernel)\n",
    "            img_fluo = img_fluo_raw - tophat_filter\n",
    "\n",
    "        # Get pixels of spot\n",
    "        points = np.asarray( eval(spot_idx_k) )\n",
    "        ys = points[:,0]; xs = points[:,1]\n",
    "\n",
    "        # Zoom on the image around spot\n",
    "        crop_margin = 25\n",
    "        x_min = np.amin(xs); x_max = np.amax(xs); y_min = np.amin(ys); y_max = np.amax(ys);\n",
    "        # Get zoomed raw image\n",
    "        img_fluo_raw_cropped = img_fluo_raw[ max(x_min-crop_margin,0):x_max+crop_margin, max(y_min-crop_margin,0):y_max+crop_margin, :]\n",
    "        # Get zoomed fluo image\n",
    "        img_fluo_cropped = img_fluo[ max(x_min-crop_margin,0):x_max+crop_margin, max(y_min-crop_margin,0):y_max+crop_margin, :]\n",
    "\n",
    "        # Save FP examples to disk\n",
    "        path_to_dump_FP_viz = os.path.join(\".\",\"crossval_results_v3\",\"FP_viz\",fold)\n",
    "        if not os.path.exists(path_to_dump_FP_viz): \n",
    "            os.makedirs(path_to_dump_FP_viz)\n",
    "        # Save raw image \n",
    "        plt.close('all')\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15,15), sharex=True, sharey=True)\n",
    "        ax.imshow(img_fluo_raw, interpolation='nearest')\n",
    "        margin = 1\n",
    "        c = plt.Rectangle((y_min - margin, x_min - margin), y_max-y_min + 2*margin, x_max-x_min + 2*margin,color=[1.,0,0], lw=1.0, fill=False)\n",
    "        ax.add_artist(c)\n",
    "        plt.imshow(img_fluo_raw, alpha=0.6)\n",
    "        plt.savefig( os.path.join(path_to_dump_FP_viz, fold+'_'+foldername_k+filename_k[:-4]+'_'+str(k)+'_box_raw.png' ))\n",
    "        # Save zoomed raw image\n",
    "        plt.close('all')\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10,10), sharex=True, sharey=True)\n",
    "        ax.imshow(img_fluo_raw_cropped, interpolation='nearest')\n",
    "        margin = 1\n",
    "        c = plt.Rectangle((crop_margin - margin, crop_margin - margin), y_max-y_min + 2*margin, x_max-x_min + 2*margin,color=[0.5,0,0], lw=1.0, fill=False)\n",
    "        ax.add_artist(c)\n",
    "        plt.imshow(img_fluo_raw_cropped, alpha=0.6)\n",
    "        plt.savefig( os.path.join(path_to_dump_FP_viz, fold+'_'+foldername_k+filename_k[:-4]+'_'+str(k)+'_cropbox_raw.png' ))\n",
    "        # Save zoomed fluo image\n",
    "        plt.close('all')\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10,10), sharex=True, sharey=True)\n",
    "        ax.imshow(img_fluo_cropped, interpolation='nearest')\n",
    "        margin = 1\n",
    "        c = plt.Rectangle((crop_margin - margin, crop_margin - margin), y_max-y_min + 2*margin, x_max-x_min + 2*margin,color=[0.5,0,0], lw=1.0, fill=False)\n",
    "        ax.add_artist(c)\n",
    "        plt.imshow(img_fluo_cropped, alpha=0.6)\n",
    "        plt.savefig( os.path.join(path_to_dump_FP_viz, fold+'_'+foldername_k+filename_k[:-4]+'_'+str(k)+'_cropbox_fluo.png' ))\n",
    "        \n",
    "        # We save the 4 images. We also save the meta data to find the image again\n",
    "        foldername_k_global.append(foldername_k)\n",
    "        filename_k_global.append(filename_k)\n",
    "        spot_idx_k_global.append(spot_idx_k)\n",
    "        overlap_k_global.append(overlap_k)\n",
    "            \n",
    "    # Save foldername_k_global, foldername_k_global, spot_idx_k_global, overlap_k_global to disk\n",
    "    foldername_k_global = np.reshape(foldername_k_global, [-1,1])\n",
    "    filename_k_global = np.reshape(filename_k_global, [-1,1])\n",
    "    spot_idx_k_global = np.reshape(spot_idx_k_global, [-1,1])\n",
    "    overlap_k_global = np.reshape(overlap_k_global, [-1,1])\n",
    "\n",
    "    # Book keeping\n",
    "    if not os.path.exists(os.path.join(path_to_dump_FP_viz, str(fold))): \n",
    "        os.makedirs( os.path.join(path_to_dump_FP_viz, str(fold) ) )\n",
    "    # foldername_k_global\n",
    "    with open( os.path.join(path_to_dump_FP_viz, str(fold),\"FP_foldername_k_global.csv\"), \"wb\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(foldername_k_global)\n",
    "    # filename_k_global\n",
    "    with open( os.path.join(path_to_dump_FP_viz, str(fold),\"FP_filename_k_global.csv\"), \"wb\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(filename_k_global)\n",
    "    # spot_idx_k_global\n",
    "    with open( os.path.join(path_to_dump_FP_viz, str(fold),\"FP_spot_idx_k_global.csv\"), \"wb\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(spot_idx_k_global)\n",
    "    # overlap_k_global\n",
    "    with open( os.path.join(path_to_dump_FP_viz, str(fold),\"FP_overlap_k_global.csv\"), \"wb\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(overlap_k_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to csv\n",
    "print( len(fold_global))\n",
    "print(len(auc_global))\n",
    "print(len(fpr_value_global))\n",
    "print(len(fnr_value_global))\n",
    "\n",
    "fold_global = np.reshape(fold_global, [-1,1])\n",
    "auc_global = np.reshape(auc_global, [-1,1])\n",
    "fpr_value_global = np.reshape(fpr_value_global, [-1,1])\n",
    "fnr_value_global = np.reshape(fnr_value_global, [-1,1])\n",
    "print(fold_global.shape)\n",
    "print(auc_global.shape)\n",
    "print(fpr_value_global.shape)\n",
    "print(fnr_value_global.shape)\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"fnrs_global.csv\") , \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(fnrs_global)\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"fprs_global.csv\") , \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(fprs_global)\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"thresholds_global.csv\") , \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(thresholds_global)\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"fold_global.csv\") , \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(fold_global)\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"auc_global.csv\") , \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(auc_global)\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"fpr_value_global.csv\") , \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(fpr_value_global)\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"fnr_value_global.csv\") , \"wb\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(fnr_value_global)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError('WIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Load results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results_v2 from csv\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"fnrs_global.csv\")  , 'rb' ) as fp:\n",
    "    reader = csv.reader(fp, delimiter=',', quotechar='\"')\n",
    "    fnrs_global = [row for row in reader]\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"fprs_global.csv\")  , 'rb' ) as fp:\n",
    "    reader = csv.reader(fp, delimiter=',', quotechar='\"')\n",
    "    fprs_global = [row for row in reader]\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"thresholds_global.csv\")  , 'rb' ) as fp:\n",
    "    reader = csv.reader(fp, delimiter=',', quotechar='\"')\n",
    "    thresholds_global = [row for row in reader]\n",
    "    \n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"fold_global.csv\")  , 'rb' ) as fp:\n",
    "    reader = csv.reader(fp, delimiter=',', quotechar='\"')\n",
    "    fold_global = [row for row in reader]\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"auc_global.csv\")  , 'rb' ) as fp:\n",
    "    reader = csv.reader(fp, delimiter=',', quotechar='\"')\n",
    "    auc_global = [row for row in reader]\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"fpr_value_global.csv\")  , 'rb' ) as fp:\n",
    "    reader = csv.reader(fp, delimiter=',', quotechar='\"')\n",
    "    fpr_value_global = [row for row in reader]\n",
    "\n",
    "with open( os.path.join(\".\",\"crossval_results_v3\",\"fnr_value_global.csv\")  , 'rb' ) as fp:\n",
    "    reader = csv.reader(fp, delimiter=',', quotechar='\"')\n",
    "    fnr_value_global = [row for row in reader]\n",
    "\n",
    "    \n",
    "fnrs_global = map( lambda x : map(eval,x), fnrs_global)\n",
    "fprs_global = map( lambda x : map(eval,x), fprs_global)\n",
    "thresholds_global = map( lambda x : map(eval,x), thresholds_global)\n",
    "\n",
    "fold_global = map( lambda x : x[0], fold_global)\n",
    "auc_global = map( lambda x : eval(x[0]), auc_global)\n",
    "fpr_value_global = map( lambda x : eval(x[0]), fpr_value_global)\n",
    "fnr_value_global = map( lambda x : eval(x[0]), fnr_value_global)\n",
    "\n",
    "print(len(fnrs_global))\n",
    "print(len(fprs_global))\n",
    "print(len(thresholds_global))\n",
    "print(len(fold_global))\n",
    "print(len(auc_global))\n",
    "print(len(fpr_value_global))\n",
    "print(len(fnr_value_global))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC\n",
    "auc_mean = np.mean(auc_global)\n",
    "auc_std = np.std(auc_global)\n",
    "print('auc_mean: ',auc_mean)\n",
    "print('auc_std: ',auc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPR\n",
    "fpr_mean = np.mean(fpr_value_global)\n",
    "fpr_std = np.std(fpr_value_global)\n",
    "print('fpr_mean: ',fpr_mean)\n",
    "print('fpr_std: ',fpr_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify which AUC curve is the closest to the mean one (e.g. compare AUCs to mean AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_global_mean = np.mean(auc_global)\n",
    "temp = np.abs(auc_global - auc_global_mean)\n",
    "curve_closest_to_mean = np.argmin(temp)\n",
    "curve_closest_to_mean\n",
    "# curve_closest_to_mean = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FPR vs FNR curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_folds = len(fnrs_global)\n",
    "plt.figure( figsize=(15,10) )\n",
    "\n",
    "# Iterate over the folds, except the mean curve\n",
    "for i in range(n_folds):\n",
    "    \n",
    "    if i==curve_closest_to_mean:\n",
    "        # we plot the 'mean' curve at the end\n",
    "        continue\n",
    "\n",
    "    fnrs = fnrs_global[i]\n",
    "    fprs = fprs_global[i]\n",
    "    thresholds = thresholds_global[i]\n",
    "    fold = fold_global[i]\n",
    "    assert len(fnrs) == len(fprs)\n",
    "    assert len(fnrs) == len(thresholds)\n",
    "    \n",
    "    # Plot FPR vs FNR on test data\n",
    "    lw = 1\n",
    "    plt.plot(fnrs, fprs, color='gray',lw=lw, alpha=0.8)\n",
    "\n",
    "# Plot the mean curve\n",
    "i=curve_closest_to_mean\n",
    "fnrs = fnrs_global[i]\n",
    "fprs = fprs_global[i]\n",
    "thresholds = thresholds_global[i]\n",
    "fold = fold_global[i]\n",
    "assert len(fnrs) == len(fprs)\n",
    "assert len(fnrs) == len(thresholds)\n",
    "plt.plot(fnrs, fprs, color='darkorange',lw=3)\n",
    "\n",
    "plt.axvline(0.1, c='gray', ls='--')\n",
    "plt.xlabel('FNR'); plt.ylabel('FPR'); plt.legend(loc=\"lower right\");\n",
    "plt.yscale('log'); plt.xscale('log'); plt.xlim([0.00001,1.]); plt.ylim([0.0000001,1.]);\n",
    "plt.title('FPR vs FNR')\n",
    "plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = len(fnrs_global)\n",
    "plt.figure( figsize=(15,10) )\n",
    "\n",
    "# Iterate over the folds\n",
    "for i in range(n_folds):\n",
    "    \n",
    "    if i==curve_closest_to_mean:\n",
    "        # we plot the 'mean' curve at the end\n",
    "        continue\n",
    "\n",
    "    fnrs = fnrs_global[i]\n",
    "    fprs = fprs_global[i]\n",
    "    thresholds = thresholds_global[i]\n",
    "    fold = fold_global[i]\n",
    "    assert len(fnrs) == len(fprs)\n",
    "    assert len(fnrs) == len(thresholds)\n",
    "    \n",
    "    ### \n",
    "    # Plots for error analysis: we plot the learning curves \n",
    "    ###\n",
    "    # Plot FPR+FNR vs decision thresholds\n",
    "    plt.plot(thresholds, fprs, color='gray',lw=1, alpha=0.8)#, label='FPR')#+fold)\n",
    "    plt.plot(thresholds, fnrs, color='gray',lw=1, alpha=0.8)#, label='FNR')#+fold)\n",
    "\n",
    "    \n",
    "    \n",
    "# Plot the mean curve\n",
    "i=curve_closest_to_mean\n",
    "fnrs = fnrs_global[i]\n",
    "fprs = fprs_global[i]\n",
    "thresholds = thresholds_global[i]\n",
    "fold = fold_global[i]\n",
    "assert len(fnrs) == len(fprs)\n",
    "assert len(fnrs) == len(thresholds)\n",
    "plt.plot(thresholds, fprs, color='darkorange',lw=3, label='FPR')#+fold)\n",
    "plt.plot(thresholds, fnrs, color='green',lw=3, label='FNR')#+fold)\n",
    "    \n",
    "plt.axhline(0.1, c='green', ls='--')\n",
    "plt.xlabel('thresholds'); plt.ylabel('FPR and FNR');plt.legend(loc=\"lower right\")\n",
    "plt.yscale('log'); plt.xlim([0.,1.1]); plt.ylim([0.,1.1]);\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
